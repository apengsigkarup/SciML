{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d30d2863",
   "metadata": {},
   "source": [
    "# Ph.D. Course on \"Advanced Machine Learning\" August 23rd, 2024\n",
    "## - Physics-Informed Machine Learning and Surrogate Modelling\n",
    "\n",
    "This notebook is a part of exercises in the PhD Course that complement the lecture. \n",
    "\n",
    "To make sure your environment is setup to perform the exercises please visit\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; https://github.com/apengsigkarup/SciML\n",
    "\n",
    "and follow the instructions for installing the environment.\n",
    "\n",
    "If you have not already done so, please download all the data files and codes from this github repository and report any errors or issues with the materials to Allan Peter Engsig-Karup (apek@dtu.dk)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fc5161",
   "metadata": {},
   "source": [
    "### Python modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1b9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e0e72-77e9-4077-b649-ca8a3898af89",
   "metadata": {},
   "source": [
    "### Detect device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4181291b-f7a1-47cc-a749-057aa68074f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Architecture: ARM\n",
      "CPU: arm\n"
     ]
    }
   ],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Check for ARM architecture\n",
    "architecture = platform.machine()\n",
    "if 'arm' in architecture or 'aarch' in architecture:\n",
    "    print(\"Architecture: ARM\")\n",
    "else:\n",
    "    print(f\"Architecture: {architecture}\")\n",
    "\n",
    "# Optional: More detailed GPU check\n",
    "if device == \"cuda\":\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "# Check for CPU information\n",
    "cpu_info = platform.processor()\n",
    "if cpu_info:\n",
    "    print(f\"CPU: {cpu_info}\")\n",
    "else:\n",
    "    print(\"CPU information not available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e184c36d",
   "metadata": {},
   "source": [
    "### Define Precision used in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffdcaa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default tensor type in PyTorch to float64 precision\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b20b3f",
   "metadata": {},
   "source": [
    "## Exercise 00: Getting Started\n",
    "\n",
    "The purpose of this notebook is to make sure that your enviroment is ready for the exercises. This is done by testing the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e17f3",
   "metadata": {},
   "source": [
    "### 1. Define and create a simple neural network \n",
    "\n",
    "Let's define a class for a simple neural network using Pytorch and print the model configuration. The network is to have on hidden layer and take an input vector of dimension 50, a hidden layer with 100 neurons and an output layer of 10 nodes. All nodes should include bias terms and the hidden layer should be activated using a nonlinear ReLu function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f455989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (hidden): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "Total trainable parameters: 6110\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "class SimpleNN(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Define the hidden layer with 100 neurons and bias \n",
    "        self.hidden = nn.Linear(in_features=50, out_features=100) \n",
    "        # Define the output layer with 10 neurons and bias \n",
    "        self.output = nn.Linear(in_features=100, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Activation function for hidden layer \n",
    "        x = torch.tanh(self.hidden(x))\n",
    "        #    Output layer\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network \n",
    "model = SimpleNN()\n",
    "print(model)\n",
    "print(f'Total trainable parameters: {count_parameters(model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f6a56",
   "metadata": {},
   "source": [
    "### 2. Prepare training of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab6e0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()\n",
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f81b3a",
   "metadata": {},
   "source": [
    "### 3. Store and load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea9564ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "# Load model and optimizer state_dict\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "# Save model and optimizer state_dict\n",
    "def save_checkpoint(state, filename=\"default_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c33bb76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "SAVE_MODEL_FILE = \"model_statedict.pth.tar\"\n",
    "checkpoint = {\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"optimizer\": optimizer.state_dict(),\n",
    "}\n",
    "save_checkpoint(checkpoint, filename=SAVE_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bcc0d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "LOAD_MODEL_FILE = \"model_statedict.pth.tar\"\n",
    "load_checkpoint(torch.load(LOAD_MODEL_FILE), model, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3295a",
   "metadata": {},
   "source": [
    "### 4. Store a model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9fc9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
